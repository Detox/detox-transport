/**
 * @package Detox transport
 * @author  Nazar Mokrynskyi <nazar@mokrynskyi.com>
 * @license 0BSD
 */
# 65 KiB is what is enough for DHT messages and will also be enough for routing data, bigger data will be multiplexed on higher levels when necessary
const MAX_DATA_SIZE				= 2 ** 16 - 2
const MAX_COMPRESSED_DATA_SIZE	= MAX_DATA_SIZE - 1
# Fixed packet size for all communications on peer connection
const PACKET_SIZE				= 512

/**
 * @param {!Array<!Uint8Array>}	buffer
 * @param {!Uint8Array}			new_array
 */
!function update_dictionary_buffer (buffer, new_array)
	buffer[0]	= buffer[1]
	buffer[1]	= buffer[2]
	buffer[2]	= buffer[3]
	buffer[3]	= buffer[4]
	buffer[4]	= new_array

/**
 * @param {!Object=} wrtc
 */
function Wrapper (detox-utils, fixed-size-multiplexer, async-eventer, pako, simple-peer, wrtc)
	array2string	= detox-utils['array2string']
	string2array	= detox-utils['string2array']
	concat_arrays	= detox-utils['concat_arrays']
	error_handler	= detox-utils['error_handler']
	ArrayMap		= detox-utils['ArrayMap']
	timeoutSet		= detox-utils['timeoutSet']
	empty_array		= new Uint8Array(0)
	/**
	 * @constructor
	 *
	 * @param {!Uint8Array}		id								Own ID
	 * @param {!Uint8Array}		peer_id							ID of a peer
	 * @param {boolean}			initiator
	 * @param {!Array<!Object>}	ice_servers
	 * @param {number}			packets_per_second				Each packet send in each direction has exactly the same size and packets are sent at fixed rate (>= 1)
	 * @param {number}			uncompressed_commands_offset	Commands with number less than this will be compressed/decompressed with zlib
	 *
	 * @return {!P2P_transport}
	 */
	!function P2P_transport (id, peer_id, initiator, ice_servers, packets_per_second, uncompressed_commands_offset)
		if !(@ instanceof P2P_transport)
			return new P2P_transport(id, peer_id, initiator, ice_servers, packets_per_second, uncompressed_commands_offset)
		async-eventer.call(@)

		@_id							= id
		@_peer_id						= peer_id
		@_ice_servers					= ice_servers
		@_uncompressed_commands_offset	= uncompressed_commands_offset
		@_send_delay					= 1000 / packets_per_second
		@_multiplexer					= fixed-size-multiplexer['Multiplexer'](MAX_DATA_SIZE, PACKET_SIZE)
		@_demultiplexer					= fixed-size-multiplexer['Demultiplexer'](MAX_DATA_SIZE, PACKET_SIZE)
		@_send_zlib_buffer				= [empty_array, empty_array, empty_array, empty_array, empty_array]
		@_receive_zlib_buffer			= [empty_array, empty_array, empty_array, empty_array, empty_array]
		@_init_peer(initiator)

	P2P_transport:: =
		/**
		 * @param {boolean} initiator
		 */
		_init_peer	: (initiator) !->
			if @_connected
				return
			@_initiator		= initiator
			@_sending		= initiator
			old_instance	= @_peer
			instance		= simple-peer(
				'config'	:
					'iceServers'	: @_ice_servers
				'initiator'	: initiator
				'trickle'	: false
				'wrtc'		: wrtc
			)
				..'once'('signal', (signal) !~>
					if @_destroyed || @_peer != instance
						return
					@'fire'('signal', concat_arrays([
						[if initiator then 1 else 0]
						string2array(signal['sdp'])
					]))
				)
				..'once'('connect', !~>
					if @_destroyed || @_peer != instance
						return
					@'fire'('connected')
					@_connected	= true
					@_last_sent	= +(new Date)
					if @_sending
						@_real_send()
				)
				..'once'('close', !~>
					if @_peer != instance
						return
					@'fire'('disconnected')
					@'destroy'()
				)
				..'on'('data', (data) !~>
					if @_destroyed
						return
					# Data are sent in alternating order, sending data when receiving is expected violates the protocol
					# Data size must be exactly one packet size
					if @_sending || data.length != PACKET_SIZE
						@'destroy'()
					else
						@_demultiplexer['feed'](data)
						while @_demultiplexer['have_more_data']()
							demultiplexed_data	= @_demultiplexer['get_data']()
							command				= demultiplexed_data[0]
							command_data		= demultiplexed_data.subarray(1)
							if command < @_uncompressed_commands_offset
								command_data	= @_zlib_decompress(command_data)
							@'fire'('data', command, command_data)
						@_sending	= true
						@_real_send()
				)
				..'on'('error', error_handler)
			@_peer	= instance
			if old_instance
				old_instance['destroy']()
		/**
		 * @param {!Uint8Array} signal As generated by `signal` event
		 */
		'signal' : (signal) !->
			if @_destroyed
				return
			offer	= Boolean(signal[0])
			if offer == @_initiator
				for item, key in @_id
					if item == @_peer_id[key]
						continue
					if item > @_peer_id[key]
						# If this node's ID if bigger, then connection initiated by this node will win and the other side will
						# discard its initiated connection
						return
					else
						# Otherwise our connection is discarded and we proceed with connection initiated by the other side
						@_init_peer(false)
						break
			@_peer['signal'](
				'type'	: if @_initiator then 'answer' else 'offer'
				'sdp'	: array2string(signal.subarray(1))
			)
		'update_peer_id' : (peer_id) !->
			@_peer_id	= peer_id
		/**
		 * @param {number}		command
		 * @param {!Uint8Array}	data
		 */
		'send' : (command, data) !->
			if @_destroyed || data.length > MAX_DATA_SIZE
				return
			# We only compress DHT commands data
			if command < @_uncompressed_commands_offset
				if data.length > MAX_COMPRESSED_DATA_SIZE
					return
				data	= @_zlib_compress(data)
			data_with_header	= concat_arrays([[command], data])
			@_multiplexer['feed'](data_with_header)
		'destroy' : !->
			if @_destroyed
				return
			@_destroyed	= true
			clearTimeout(@_timeout)
			@_peer['destroy']()
		/**
		 * Send a block of multiplexed data to the other side
		 */
		_real_send : !->
			# Subtract from necessary delay actual amount of time already passed and make sure it is not negative
			delay		= Math.max(0, @_send_delay - (new Date - @_last_sent))
			@_timeout	= setTimeout (!~>
				if @_destroyed
					return
				# In rare cases we might get exceptions like `InvalidStateError`, don't let the whole thing crash because of this
				try
					@_peer['send'](@_multiplexer['get_block']())
					@_sending	= false
					@_last_sent	= +(new Date)
			), delay
		/**
		 * @param {!Uint8Array} data
		 *
		 * @return {!Uint8Array}
		 */
		_zlib_compress : (data) ->
			result	= pako['deflate'](data, {
				'dictionary'	: concat_arrays(@_send_zlib_buffer)
				'level'			: 1
			})
			update_dictionary_buffer(@_send_zlib_buffer, data)
			if result.length > MAX_COMPRESSED_DATA_SIZE
				concat_arrays([[0], data])
			else
				concat_arrays([[1], result])
		/**
		 * @param {!Uint8Array} data
		 *
		 * @return {!Uint8Array}
		 */
		_zlib_decompress : (data) ->
			compressed	= data[0]
			data		= data.subarray(1)
			if compressed
				result	= pako['inflate'](data, {
					'dictionary'	: concat_arrays(@_receive_zlib_buffer)
				})
			else
				result	= data
			update_dictionary_buffer(@_receive_zlib_buffer, result)
			result
	P2P_transport:: = Object.assign(Object.create(async-eventer::), P2P_transport::)
	Object.defineProperty(P2P_transport::, 'constructor', {value: P2P_transport})
	/**
	 * @constructor
	 *
	 * @param {!Uint8Array}		id								Own ID
	 * @param {!Array<!Object>}	ice_servers
	 * @param {number}			packets_per_second				Each packet send in each direction has exactly the same size and packets are sent at fixed rate (>= 1)
	 * @param {number}			uncompressed_commands_offset	Commands with number less than this will be compressed/decompressed with zlib
	 * @param {number}			connect_timeout					How many seconds since `signal` generation to wait for connection before failing
	 *
	 * @return {!Transport}
	 */
	!function Transport (id, ice_servers, packets_per_second, uncompressed_commands_offset, connect_timeout)
		if !(@ instanceof Transport)
			return new Transport(id, ice_servers, packets_per_second, uncompressed_commands_offset, connect_timeout)
		async-eventer.call(@)

		@_id							= id
		@_pending_connections			= ArrayMap()
		@_connections					= ArrayMap()
		@_timeouts						= new Set
		@_ice_servers					= ice_servers
		@_packets_per_second			= packets_per_second
		@_uncompressed_commands_offset	= uncompressed_commands_offset
		@_connect_timeout				= connect_timeout
		@_connection_to_id_map			= new WeakMap

	Transport:: =
		/**
		 * @param {boolean}		initiator
		 * @param {!Uint8Array}	peer_id
		 *
		 * @return {P2P_transport}
		 */
		'create_connection' : (initiator, peer_id) ->
			if @_destroyed
				return null
			connection	= @_pending_connections.get(peer_id) || @_connections.get(peer_id)
			if connection
				return connection
			connection	= P2P_transport(@_id, peer_id, initiator, @_ice_servers, @_packets_per_second, @_uncompressed_commands_offset)
				.'on'('data', (command, command_data) !~>
					if @_destroyed
						return
					peer_id	= @_connection_to_id_map.get(connection)
					@'fire'('data', peer_id, command, command_data)
				)
				.'once'('signal', (signal) !~>
					if @_destroyed
						return
					peer_id	= @_connection_to_id_map.get(connection)
					@'fire'('signal', peer_id, signal)
					# Make sure connection takes no longer than needed
					@_timeout(connection, 'connected')
				)
				.'once'('connected', !~>
					peer_id	= @_connection_to_id_map.get(connection)
					if @_destroyed || !@_pending_connections.has(peer_id)
						return
					@_pending_connections.delete(peer_id)
					@_connections.set(peer_id, connection)
					@'fire'('connected', peer_id)
				)
				.'once'('disconnected', !~>
					if @_destroyed
						return
					peer_id	= @_connection_to_id_map.get(connection)
					@_pending_connections.delete(peer_id)
					@_connections.delete(peer_id)
					@'fire'('disconnected', peer_id)
				)
			@_connection_to_id_map.set(connection, peer_id)
			# `signal` event might not be fired ever, so create timeout here
			@_timeout(connection, 'signal')
			@_pending_connections.set(peer_id, connection)
			connection
		/**
		 * @param {!Uint8Array}	old_peer_id
		 * @param {!Uint8Array}	new_peer_id
		 *
		 * @return {boolean}
		 */
		'update_peer_id' : (old_peer_id, new_peer_id) ->
			if @_pending_connections.has(new_peer_id) || @_connections.has(new_peer_id)
				return false
			connection	= @_pending_connections.get(old_peer_id)
			if connection
				@_connection_to_id_map.set(connection, new_peer_id)
				@_pending_connections.delete(old_peer_id)
				@_pending_connections.set(new_peer_id, connection)
				connection['update_peer_id'](new_peer_id)
				return true
			connection	= @_connections.get(old_peer_id)
			if connection
				@_connection_to_id_map.set(connection, new_peer_id)
				@_connections.delete(old_peer_id)
				@_connections.set(new_peer_id, connection)
				connection['update_peer_id'](new_peer_id)
				return true
			false
		/**
		 * @param {!P2P_transport} connection
		 */
		_timeout : (connection, event) !->
			timeout	= timeoutSet(@_connect_timeout, !->
				connection['destroy']()
			)
			@_timeouts.add(timeout)
			connection['once'](event, !~>
				@_timeouts.delete(timeout)
				clearTimeout(timeout)
			)
		/**
		 * @param {!Uint8Array} peer_id
		 */
		'destroy_connection' : (peer_id) !->
			connection	= @_pending_connections.get(peer_id) || @_connections.get(peer_id)
			if connection
				connection['destroy']()
		/**
		 * @param {!Uint8Array} peer_id
		 * @param {!Uint8Array} signal
		 */
		'signal' : (peer_id, signal) !->
			if @_destroyed
				return
			connection	= @_pending_connections.get(peer_id)
			if connection
				connection['signal'](signal)
		/**
		 * @param {!Uint8Array}	peer_id
		 * @param {number}		command
		 * @param {!Uint8Array}	command_data
		 */
		'send' : (peer_id, command, command_data) !->
			if @_destroyed
				return
			connection	= @_connections.get(peer_id)
			if connection
				connection['send'](command, command_data)
		'destroy' : !->
			if @_destroyed
				return
			@_destroyed	= true
			@_pending_connections.forEach (connection) !->
				connection['destroy']()
			@_connections.forEach (connection) !->
				connection['destroy']()
			@_timeouts.forEach (timeout) !->
				clearTimeout(timeout)
	Transport:: = Object.assign(Object.create(async-eventer::), Transport::)
	Object.defineProperty(Transport::, 'constructor', {value: Transport})
	{
		'P2P_transport'				: P2P_transport
		'Transport'					: Transport
		'MAX_DATA_SIZE'				: MAX_DATA_SIZE
		'MAX_COMPRESSED_DATA_SIZE'	: MAX_COMPRESSED_DATA_SIZE
	}

# NOTE: `wrtc` dependency is the last one and only specified for CommonJS, make sure to insert new dependencies before it
if typeof define == 'function' && define['amd']
	# AMD
	define(['@detox/utils', 'fixed-size-multiplexer', 'async-eventer', 'pako', '@detox/simple-peer'], Wrapper)
else if typeof exports == 'object'
	# CommonJS
	module.exports = Wrapper(require('@detox/utils'), require('fixed-size-multiplexer'), require('async-eventer'), require('pako'), require('@detox/simple-peer'), require('wrtc'))
else
	# Browser globals
	@'detox_transport' = Wrapper(@'detox_utils', @'fixed_size_multiplexer', @'async_eventer', @'pako', @'SimplePeer')
