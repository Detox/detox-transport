/**
 * @package Detox transport
 * @author  Nazar Mokrynskyi <nazar@mokrynskyi.com>
 * @license 0BSD
 */
const ROUTING_COMMANDS_OFFSET	= 10 # 0..9 are reserved as DHT commands

# Length of Ed25519 public key in bytes
const PUBLIC_KEY_LENGTH				= 32
# ChaChaPoly+BLAKE2b
const MAC_LENGTH					= 16
# Max time in seconds allowed for routing path segment creation after which creation is considered failed
const ROUTING_PATH_SEGMENT_TIMEOUT	= 10
# 65 KiB is what is enough for DHT messages and will also be enough for routing data, bigger data will be multiplexed on higher levels when necessary
const MAX_DATA_SIZE					= 2 ** 16 - 1
# Fixed packet size for all communications on peer connection
const PACKET_SIZE					= 512
# 3 bytes (2 for multiplexer and 1 for command) smaller than packet size in DHT in order to avoid fragmentation when sending over peer connection
const ROUTER_PACKET_SIZE			= PACKET_SIZE - 3
# If connection was not established during this time (seconds) then assume connection failure
const PEER_CONNECTION_TIMEOUT		= 30

/**
 * @param {!Array<!Uint8Array>}	buffer
 * @param {!Uint8Array}			new_array
 */
!function update_dictionary_buffer (buffer, new_array)
	buffer[0]	= buffer[1]
	buffer[1]	= buffer[2]
	buffer[2]	= buffer[3]
	buffer[3]	= buffer[4]
	buffer[4]	= new_array

function Wrapper (detox-crypto, detox-dht, detox-utils, ronion, fixed-size-multiplexer, async-eventer, pako, simple-peer, wrtc)
	array2string		= detox-utils['array2string']
	string2array		= detox-utils['string2array']
	are_arrays_equal	= detox-utils['are_arrays_equal']
	concat_arrays		= detox-utils['concat_arrays']
	ArrayMap			= detox-utils['ArrayMap']
	/**
	 * @constructor
	 *
	 * @param {boolean}			initiator
	 * @param {!Array<!Object>}	ice_servers
	 * @param {number}			packets_per_second	Each packet send in each direction has exactly the same size and packets are sent at fixed rate (>= 1)
	 *
	 * @return {!DHT}
	 */
	!function P2P_transport (initiator, ice_servers, packets_per_second)
		if !(@ instanceof P2P_transport)
			return new P2P_transport(ice_servers, packets_per_second)
		async-eventer.call(@)

		@_initiator	= initiator
		# TODO: Timeouts (PEER_CONNECTION_TIMEOUT)?
		# TODO: Signatures here?
		@_peer		= simple-peer(
			'config'	:
				'iceServers'	: ice_servers
			'initiator'	: initiator
			'trickle'	: false
			'wrtc'		: wrtc
		)

		@_signal	= new Promise (resolve, reject) !~>
			@_peer
				.'once'('signal', (signal) !~>
					resolve(string2array(signal['sdp']))
				)
				.'once'('close', reject)
		@_signal.catch(->)

		@_send_delay			= 1000 / packets_per_second
		@_sending				= initiator
		@_multiplexer			= fixed-size-multiplexer['Multiplexer'](MAX_DATA_SIZE, PACKET_SIZE)
		@_demultiplexer			= fixed-size-multiplexer['Demultiplexer'](MAX_DATA_SIZE, PACKET_SIZE)
		@_send_zlib_buffer		= [new Uint8Array(0), new Uint8Array(0), new Uint8Array(0), new Uint8Array(0), new Uint8Array(0)]
		@_receive_zlib_buffer	= [new Uint8Array(0), new Uint8Array(0), new Uint8Array(0), new Uint8Array(0), new Uint8Array(0)]
		@_peer
			.'once'('connect', !~>
				@'fire'('connected')
				@_last_sent	= +(new Date)
				if @_sending
					@_real_send()
			)
			.'once'('close', !~>
				@'fire'('disconnected')
			)
			.'on'('data', (data) !~>
				# Data are sent in alternating order, sending data when receiving is expected violates the protocol
				# Data size must be exactly one packet size
				if @_sending || data.length != PACKET_SIZE
					@'destroy'()
				else
					@_demultiplexer['feed'](data)
					while @_demultiplexer['have_more_data']()
						demultiplexed_data	= @_demultiplexer['get_data']()
						command				= demultiplexed_data[0]
						command_data		= demultiplexed_data.subarray(1)
						if command < ROUTING_COMMANDS_OFFSET
							command_data	= @_zlib_decompress(command_data)
						@'fire'('data', command, command_data)
					@_sending	= true
					@_real_send()
			)

	P2P_transport:: =
		/**
		 * @return {!Promise} Resolves with `Uint8Array` signaling data
		 */
		'get_signaling' : ->
			@_signal
		/**
		 * @param {!Uint8Array} signaling As generated by `get_signaling()` method
		 */
		'set_signaling' : (signaling) !->
			@_peer['signal'](
				'type'	: if @_initiator then 'answer' else 'offer'
				'sdp'	: array2string(signaling)
			)
		/**
		 * @param {number}		command
		 * @param {!Uint8Array}	data
		 */
		'send' : (command, data) !->
			# We only compress DHT commands data
			if command < ROUTING_COMMANDS_OFFSET
				data	= @_zlib_compress(data)
			data_with_header	= new Uint8Array(data.length + 1)
				..set([command])
				..set(data, 1)
			@_multiplexer['feed'](data_with_header)
		'destroy' : !->
			@_destroyed	= true
			@_peer['destroy']()
		/**
		 * Send a block of multiplexed data to the other side
		 */
		_real_send : !->
			# Subtract from necessary delay actual amount of time already passed and make sure it is not negative
			delay	= Math.max(0, @_send_delay - (new Date - @_last_sent))
			setTimeout (!~>
				if @_destroyed
					return
				# In rare cases we might get exceptions like `InvalidStateError`, don't let the whole thing crash because of this
				try
					simple-peer::['send'].call(@, @_multiplexer['get_block']())
					@_sending	= false
					@_last_sent	= +(new Date)
				catch e
					@'emit'('error', e)
			), delay
		/**
		 * @param {!Uint8Array} data
		 *
		 * @return {!Uint8Array}
		 */
		_zlib_compress : (data) ->
			result	= pako['deflate'](data, {
				'dictionary'	: concat_arrays(@_send_zlib_buffer)
				'level'			: 1
			})
			update_dictionary_buffer(@_send_zlib_buffer, data)
			result
		/**
		 * @param {!Uint8Array} data
		 *
		 * @return {!Uint8Array}
		 */
		_zlib_decompress : (data) ->
			result	= pako['inflate'](data, {
				'dictionary'	: concat_arrays(@_receive_zlib_buffer)
			})
			update_dictionary_buffer(@_receive_zlib_buffer, result)
			result
	P2P_transport:: = Object.assign(Object.create(async-eventer::), P2P_transport::)
	Object.defineProperty(P2P_transport::, 'constructor', {value: P2P_transport})
	/**
	 * @constructor
	 *
	 * @param {!Uint8Array}	dht_public_key						Own ID (Ed25519 public key)
	 * @param {number}		bucket_size							Size of a bucket from Kademlia design
	 * @param {number}		state_history_size					How many versions of local history will be kept
	 * @param {number}		values_cache_size					How many values will be kept in cache
	 * @param {number}		fraction_of_nodes_from_same_peer	Max fraction of nodes originated from single peer allowed on lookup start
	 *
	 * @return {!DHT}
	 */
	!function DHT (dht_public_key, bucket_size, state_history_size, values_cache_size, fraction_of_nodes_from_same_peer = 0.2)
		if !(@ instanceof DHT)
			return new DHT(dht_public_key, bucket_size, state_history_size, values_cache_size, fraction_of_nodes_from_same_peer)
		async-eventer.call(@)

		@_dht	= detox-dht['DHT'](dht_public_key, bucket_size, state_history_size, values_cache_size, fraction_of_nodes_from_same_peer)
			.'on'('peer_error', (peer_id) !~>
				@'fire'('peer_error', peer_id)
			)
			.'on'('peer_warning', (peer_id) !~>
				@'fire'('peer_warning', peer_id)
			)
			.'on'('connect_to', (peer_peer_id, peer_id) !~>
				@'fire'('connect_to', peer_peer_id, peer_id)
			)
			.'on'('send', (peer_id, command, payload) !~>
				@'fire'('send', peer_id, command, payload)
			)

	DHT:: =
		/**
		 * @param {!Uint8Array}	peer_id
		 * @param {number}		command
		 * @param {!Uint8Array}	payload
		 */
		'receive' : (peer_id, command, payload) !->
			@_dht['receive'](peer_id, command, payload)
		/**
		 * @param {!Uint8Array} node_id
		 *
		 * @return {!Promise} Resolves with `!Array<!Uint8Array>`
		 */
		'lookup' : (node_id) ->
			if @_destroyed
				return Promise.reject()
			@_dht['lookup'](node_id)
		/**
		 * Generate message with introduction nodes that can later be published by any node connected to DHT (typically other node than this for anonymity)
		 *
		 * @param {!Uint8Array}			real_public_key		Ed25519 public key (real one, different from supplied in DHT constructor)
		 * @param {!Uint8Array}			real_private_key	Corresponding Ed25519 private key
		 * @param {!Array<!Uint8Array>}	introduction_nodes	Array of public keys of introduction points
		 *
		 * @return {!Uint8Array}
		 */
		'generate_announcement_message' : (real_public_key, real_private_key, introduction_nodes) ->
			time	= parseInt(+(new Date) / 1000) # In seconds, should be enough if kept as unsigned 32-bit integer which we actually do
			concat_arrays(@_dht['make_mutable_value'](real_public_key, real_private_key, time, concat_arrays(introduction_nodes)))
		/**
		 * @param {!Uint8Array} message
		 *
		 * @return {Uint8Array} Public key if signature is correct, `null` otherwise
		 */
		'verify_announcement_message' : (message) ->
			real_public_key	= message.subarray(0, PUBLIC_KEY_LENGTH)
			data			= message.subarray(PUBLIC_KEY_LENGTH)
			payload			= @_dht['verify_value'](real_public_key, data)
			# If value is not valid or length doesn't fit certain number of introduction nodes exactly
			if !payload || (payload[1].length % PUBLIC_KEY_LENGTH)
				null
			else
				real_public_key
		/**
		 * Publish message with introduction nodes (typically happens on different node than `generate_announcement_message()`)
		 *
		 * @param {!Uint8Array} message
		 */
		'publish_announcement_message' : (message) !->
			if @_destroyed
				return
			real_public_key	= message.subarray(0, PUBLIC_KEY_LENGTH)
			data			= message.subarray(PUBLIC_KEY_LENGTH)
			@_dht['put_value'](real_public_key, data)
		/**
		 * Find nodes in DHT that are acting as introduction points for specified public key
		 *
		 * @param {!Uint8Array}	target_public_key
		 *
		 * @return {!Promise} Resolves with `!Array<!Uint8Array>`
		 */
		'find_introduction_nodes' : (target_public_key) ->
			if @_destroyed
				return Promise.reject()
			@_dht['get_value'](target_public_key).then (introduction_nodes_bulk) ->
				if introduction_nodes_bulk.length % PUBLIC_KEY_LENGTH != 0
					throw ''
				introduction_nodes	= []
				for i from 0 til introduction_nodes_bulk.length / PUBLIC_KEY_LENGTH
					introduction_nodes.push(introduction_nodes_bulk.subarray(i * PUBLIC_KEY_LENGTH, (i + 1) * PUBLIC_KEY_LENGTH))
				introduction_nodes
		'destroy' : !->
			if @_destroyed
				return
			@_destroyed	= true
			@_dht['destroy']()
	DHT:: = Object.assign(Object.create(async-eventer::), DHT::)
	Object.defineProperty(DHT::, 'constructor', {value: DHT})
	/**
	 * @constructor
	 *
	 * @param {!Uint8Array}	dht_private_key			X25519 private key that corresponds to Ed25519 key used in `DHT` constructor
	 * @param {number}		max_pending_segments	How much segments can be in pending state per one address
	 *
	 * @return {!Router}
	 *
	 * @throws {Error}
	 */
	!function Router (dht_private_key, max_pending_segments = 10)
		if !(@ instanceof Router)
			return new Router(dht_private_key, max_pending_segments)
		async-eventer.call(@)

		@_encryptor_instances		= ArrayMap()
		@_rewrapper_instances		= ArrayMap()
		@_last_node_in_routing_path	= ArrayMap()
		@_multiplexers				= ArrayMap()
		@_demultiplexers			= ArrayMap()
		@_established_routing_paths	= ArrayMap()
		@_ronion					= ronion(ROUTER_PACKET_SIZE, PUBLIC_KEY_LENGTH, MAC_LENGTH, max_pending_segments)
			.'on'('activity', (address, segment_id) !~>
				@'fire'('activity', address, segment_id)
			)
			.'on'('create_request', (address, segment_id, command_data) !~>
				if @_destroyed
					return
				source_id	= concat_arrays([address, segment_id])
				if @_encryptor_instances.has(source_id)
					# Something wrong is happening, refuse to handle
					return
				encryptor_instance	= detox-crypto['Encryptor'](false, dht_private_key)
				try
					encryptor_instance['put_handshake_message'](command_data)
				catch
					return
				@_ronion['create_response'](address, segment_id, encryptor_instance['get_handshake_message']())
				# At this point we simply assume that initiator received our response
				@_ronion['confirm_incoming_segment_established'](address, segment_id)
				# Make sure each chunk after encryption will fit perfectly into DHT packet
				@_multiplexers.set(source_id, fixed-size-multiplexer['Multiplexer'](MAX_DATA_SIZE, @_max_packet_data_size))
				@_demultiplexers.set(source_id, fixed-size-multiplexer['Demultiplexer'](MAX_DATA_SIZE, @_max_packet_data_size))
				if !encryptor_instance['ready']()
					return
				rewrapper_instance					= encryptor_instance['get_rewrapper_keys']().map(detox-crypto['Rewrapper'])
				encryptor_instances					= ArrayMap()
				encryptor_instances.set(address, encryptor_instance)
				rewrapper_instances					= ArrayMap()
				rewrapper_instances.set(address, rewrapper_instance)
				@_encryptor_instances.set(source_id, encryptor_instances)
				@_rewrapper_instances.set(source_id, rewrapper_instances)
				@_last_node_in_routing_path.set(source_id, address)
			)
			.'on'('send', (address, packet) !~>
				@'fire'('send', address, packet)
			)
			.'on'('data', (address, segment_id, target_address, command, command_data) !~>
				if @_destroyed
					return
				source_id					= concat_arrays([address, segment_id])
				last_node_in_routing_path	= @_last_node_in_routing_path.get(source_id)
				if !are_arrays_equal(target_address, last_node_in_routing_path)
					# We only accept data back from responder
					return
				demultiplexer				= @_demultiplexers.get(source_id)
				if !demultiplexer
					return
				demultiplexer['feed'](command_data)
				# Data are always more or equal to block size, so no need to do `while` loop
				if demultiplexer['have_more_data']()
					data	= demultiplexer['get_data']()
					@'fire'('data', address, segment_id, command, data)
			)
			.'on'('encrypt', (data) !~>
				if @_destroyed
					return
				address				= data['address']
				segment_id			= data['segment_id']
				target_address		= data['target_address']
				plaintext			= data['plaintext']
				source_id			= concat_arrays([address, segment_id])
				encryptor_instance	= @_encryptor_instances.get(source_id)?.get(target_address)
				if !encryptor_instance || !encryptor_instance['ready']()
					return
				data['ciphertext']	= encryptor_instance['encrypt'](plaintext)
			)
			.'on'('decrypt', (data) !~>
				if @_destroyed
					return
				address				= data['address']
				segment_id			= data['segment_id']
				target_address		= data['target_address']
				ciphertext			= data['ciphertext']
				source_id			= concat_arrays([address, segment_id])
				encryptor_instance	= @_encryptor_instances.get(source_id)?.get(target_address)
				if !encryptor_instance || !encryptor_instance['ready']()
					return
				# This can legitimately throw exceptions if ciphertext is not targeted at this node
				try
					data['plaintext']	= encryptor_instance['decrypt'](ciphertext)
				catch
					/**
					 * Since we don't use all of Ronion features and only send data between initiator and responder, we can destroy unnecessary encryptor
					 * instances and don't even try to decrypt anything, which makes data forwarding less CPU intensive
					 */
					encryptor_instance['destroy']()
					@_encryptor_instances.get(source_id).delete(target_address)
			)
			.'on'('wrap', (data) !~>
				if @_destroyed
					return
				address				= data['address']
				segment_id			= data['segment_id']
				target_address		= data['target_address']
				unwrapped			= data['unwrapped']
				source_id			= concat_arrays([address, segment_id])
				rewrapper_instance	= @_rewrapper_instances.get(source_id)?.get(target_address)?[0]
				if !rewrapper_instance
					return
				data['wrapped']	= rewrapper_instance['wrap'](unwrapped)
			)
			.'on'('unwrap', (data) !~>
				if @_destroyed
					return
				address				= data['address']
				segment_id			= data['segment_id']
				target_address		= data['target_address']
				wrapped				= data['wrapped']
				source_id			= concat_arrays([address, segment_id])
				rewrapper_instance	= @_rewrapper_instances.get(source_id)?.get(target_address)?[1]
				if !rewrapper_instance
					return
				data['unwrapped']	= rewrapper_instance['unwrap'](wrapped)
			)
		@_max_packet_data_size	= @_ronion['get_max_command_data_length']()

	Router:: =
		/**
		 * Process routing packet coming from node with specified ID
		 *
		 * @param {!Uint8Array} node_id
		 * @param {!Uint8Array} packet
		 */
		'process_packet' : (node_id, packet) !->
			if @_destroyed
				return
			@_ronion['process_packet'](node_id, packet)
		/**
		 * Construct routing path through specified nodes
		 *
		 * @param {!Array<!Uint8Array>} nodes IDs of the nodes through which routing path must be constructed, last node in the list is responder
		 *
		 * @return {!Promise} Will resolve with ID of the route or will be rejected if path construction fails
		 */
		'construct_routing_path' : (nodes) ->
			if @_destroyed
				return Promise.reject()
			nodes	= nodes.slice() # Do not modify source array
			new Promise (resolve, reject) !~>
				last_node_in_routing_path				= nodes[* - 1]
				first_node								= nodes.shift()
				encryptor_instances						= ArrayMap()
				rewrapper_instances						= ArrayMap()
				fail									= !~>
					@_destroy_routing_path(first_node, route_id)
					reject('Routing path creation failed')
				# Establishing first segment
				x25519_public_key						= detox-crypto['convert_public_key'](first_node)
				if !x25519_public_key
					fail()
					return
				first_node_encryptor_instance			= detox-crypto['Encryptor'](true, x25519_public_key)
				encryptor_instances.set(first_node, first_node_encryptor_instance)
				!~function create_response_handler (address, segment_id, command_data)
					if !are_arrays_equal(first_node, address) || !are_arrays_equal(route_id, segment_id)
						return
					clearTimeout(segment_establishment_timeout)
					@_ronion['off']('create_response', create_response_handler)
					try
						first_node_encryptor_instance['put_handshake_message'](command_data)
					catch
						fail()
						return
					if !first_node_encryptor_instance['ready']()
						fail()
						return
					rewrapper_instances.set(
						first_node
						first_node_encryptor_instance['get_rewrapper_keys']().map(detox-crypto['Rewrapper'])
					)
					@_ronion['confirm_outgoing_segment_established'](first_node, route_id)
					# Make sure each chunk after encryption will fit perfectly into DHT packet
					@_multiplexers.set(source_id, fixed-size-multiplexer['Multiplexer'](MAX_DATA_SIZE, @_max_packet_data_size))
					@_demultiplexers.set(source_id, fixed-size-multiplexer['Demultiplexer'](MAX_DATA_SIZE, @_max_packet_data_size))
					# Successfully established first segment, extending routing path further
					var current_node, current_node_encryptor_instance, segment_extension_timeout
					!~function extend_request
						if !nodes.length
							@_established_routing_paths.set(source_id, [first_node, route_id])
							resolve(route_id)
							return
						!~function extend_response_handler (address, segment_id, command_data)
							if !are_arrays_equal(first_node, address) || !are_arrays_equal(route_id, segment_id)
								return
							@_ronion['off']('extend_response', extend_response_handler)
							clearTimeout(segment_extension_timeout)
							# If last node in routing path clearly said extension failed - no need to do something else here
							if !command_data.length
								fail()
								return
							try
								current_node_encryptor_instance['put_handshake_message'](command_data)
							catch
								fail()
								return
							if !current_node_encryptor_instance['ready']()
								fail()
								return
							rewrapper_instances.set(
								current_node
								current_node_encryptor_instance['get_rewrapper_keys']().map(detox-crypto['Rewrapper'])
							)
							@_ronion['confirm_extended_path'](first_node, route_id)
							# Successfully extended routing path by one more segment, continue extending routing path further
							extend_request()
						@_ronion['on']('extend_response', extend_response_handler)
						current_node					:= nodes.shift()
						x25519_public_key				= detox-crypto['convert_public_key'](current_node)
						if !x25519_public_key
							fail()
							return
						current_node_encryptor_instance	:= detox-crypto['Encryptor'](true, x25519_public_key)
						encryptor_instances.set(current_node, current_node_encryptor_instance)
						segment_extension_timeout		:= setTimeout (!~>
							@_ronion['off']('extend_response', extend_response_handler)
							fail()
						), ROUTING_PATH_SEGMENT_TIMEOUT * 1000
						@_ronion['extend_request'](first_node, route_id, current_node, current_node_encryptor_instance['get_handshake_message']())
					extend_request()
				@_ronion['on']('create_response', create_response_handler)
				segment_establishment_timeout	= setTimeout (!~>
					@_ronion['off']('create_response', create_response_handler)
					fail()
				), ROUTING_PATH_SEGMENT_TIMEOUT * 1000
				route_id						= @_ronion['create_request'](first_node, first_node_encryptor_instance['get_handshake_message']())
				source_id						= concat_arrays([first_node, route_id])
				@_encryptor_instances.set(source_id, encryptor_instances)
				@_rewrapper_instances.set(source_id, rewrapper_instances)
				@_last_node_in_routing_path.set(source_id, last_node_in_routing_path)
		/**
		 * Destroy routing path constructed earlier
		 *
		 * @param {!Uint8Array} node_id		First node in routing path
		 * @param {!Uint8Array} route_id	Identifier returned during routing path construction
		 */
		'destroy_routing_path' : (node_id, route_id) !->
			@_destroy_routing_path(node_id, route_id)
		/**
		 * Max data size that will fit into single packet without fragmentation
		 *
		 * @return {number}
		 */
		'get_max_packet_data_size' : ->
			@_max_packet_data_size
		/**
		 * Send data to the responder on specified routing path
		 *
		 * @param {!Uint8Array}	node_id		First node in routing path
		 * @param {!Uint8Array}	route_id	Identifier returned during routing path construction
		 * @param {number}		command		Command from range `0..245`
		 * @param {!Uint8Array}	data
		 */
		'send_data' : (node_id, route_id, command, data) !->
			if @_destroyed
				return
			if data.length > MAX_DATA_SIZE
				return
			source_id		= concat_arrays([node_id, route_id])
			target_address	= @_last_node_in_routing_path.get(source_id)
			multiplexer		= @_multiplexers.get(source_id)
			if !multiplexer
				return
			multiplexer['feed'](data)
			while multiplexer['have_more_blocks']()
				data_block	= multiplexer['get_block']()
				@_ronion['data'](node_id, route_id, target_address, command, data_block)
		/**
		 * Destroy all of the routing path constructed earlier
		 */
		'destroy' : !->
			if @_destroyed
				return
			@_destroyed = true
			@_established_routing_paths.forEach ([address, segment_id]) !~>
				@_destroy_routing_path(address, segment_id)
		/**
		 * @param {!Uint8Array} address
		 * @param {!Uint8Array} segment_id
		 */
		_destroy_routing_path : (address, segment_id) !->
			source_id			= concat_arrays([address, segment_id])
			encryptor_instances	= @_encryptor_instances.get(source_id)
			if !encryptor_instances
				return
			encryptor_instances.forEach (encryptor_instance) !->
				encryptor_instance['destroy']()
			@_encryptor_instances.delete(source_id)
			@_rewrapper_instances.delete(source_id)
			@_last_node_in_routing_path.delete(source_id)
			@_multiplexers.delete(source_id)
			@_demultiplexers.delete(source_id)
			@_established_routing_paths.delete(source_id)
	Router:: = Object.assign(Object.create(async-eventer::), Router::)
	Object.defineProperty(Router::, 'constructor', {value: Router})
	{
		'ready'			: detox-crypto['ready']
		'DHT'			: DHT
		'P2P_transport'	: P2P_transport
		'Router'		: Router
		'MAX_DATA_SIZE'	: MAX_DATA_SIZE
	}

# NOTE: wrtc dependency is the last one and only specified for CommonJS, make sure to insert new dependencies before it
if typeof define == 'function' && define['amd']
	# AMD
	define(['@detox/crypto', '@detox/dht', '@detox/utils', 'ronion', 'fixed-size-multiplexer', 'async-eventer', 'pako', '@detox/simple-peer'], Wrapper)
else if typeof exports == 'object'
	# CommonJS
	module.exports = Wrapper(require('@detox/crypto'), require('@detox/dht'), require('@detox/utils'), require('ronion'), require('fixed-size-multiplexer'), require('async-eventer'), require('pako'), require('@detox/simple-peer'), require('wrtc'))
else
	# Browser globals
	@'detox_transport' = Wrapper(@'detox_crypto', @'detox_dht', @'detox_utils', @'ronion', @'fixed_size_multiplexer', @'async_eventer', @'pako', @'SimplePeer')
